import itertools

import numpy as np

import quantum_utils
from quantum_utils import kron, phi_plus_un, ket0, reshuffle_kron_vector, proj, process_operator_switch, z_onb, ket1
from utils import reciprocal_or_zero


def dependence_of_c_on_y_in_ptilde1(rho_ctb, X1, X2, Y, c_onb):
    """ Returns a measure of the dependence of c on y in the probability distribution p~1 defined in Thm 14/1/22 [p91].
    This is relevant to the one_switch_4mmts scenario, with no setting for the measurement on c.
    NOTE This function ONLY works properly if p(c = |0>)) is nonzero, i.e. if rho_ctb restricted to c is not |1>.
    """
    # Make p^1(ab|xy) correlation
    W_CO1 = kron(phi_plus_un, ket0, ket0, phi_plus_un, phi_plus_un, phi_plus_un)
    W_CO1_ordered = reshuffle_kron_vector(W_CO1, (2, 4, 0, 5, 6, 7, 8, 3, 9, 1))
    proc_op_1 = proj(W_CO1_ordered)
    cor_p1ab_xy = np.empty((2,) * 6)
    for setting_outcome_tuple in itertools.product((0, 1), repeat=6):
        a_1, a_2, b, x_1, x_2, y = setting_outcome_tuple
        tau_ctb = rho_ctb.T
        tau_a_1 = kron(proj(X1[x_1][a_1]), proj(X1[x_1][a_1])).T
        tau_a_2 = kron(proj(X2[x_2][a_2]), proj(X2[x_2][a_2])).T
        tau_Btilde = proj(Y[y][b]).T
        tau_Ctilde = proj(
            ket0).T  # conditioning on c = ket0. This should be same as tau_Ctilde = identity, since we're using W_CO1. I checked it, is is true!
        tau_Ttilde = np.identity(2)
        taus = kron(tau_ctb, tau_a_1, tau_a_2, tau_Ctilde, tau_Ttilde, tau_Btilde)
        cor_p1ab_xy[setting_outcome_tuple] = np.trace(np.matmul(proc_op_1, taus))
    # Note that cor_p1ab_xy is not normalised (it has normalisation p(c=ket0), where p is generated by proc_op_total). We could normalise, but it isn't necessary.

    # Make p(abc|xy) correlation
    proc_op_total = process_operator_switch()
    cor_pabc_xy = np.empty((2,) * 7)
    for setting_outcome_tuple in itertools.product((0, 1), repeat=7):
        a_1, a_2, b, c, x_1, x_2, y = setting_outcome_tuple
        tau_ctb = rho_ctb.T
        tau_a_1 = kron(proj(X1[x_1][a_1]), proj(X1[x_1][a_1])).T
        tau_a_2 = kron(proj(X2[x_2][a_2]), proj(X2[x_2][a_2])).T
        tau_Btilde = proj(Y[y][b]).T
        tau_Ctilde = proj(c_onb[c]).T
        tau_Ttilde = np.identity(2)
        taus = kron(tau_ctb, tau_a_1, tau_a_2, tau_Ctilde, tau_Ttilde, tau_Btilde)
        cor_pabc_xy[setting_outcome_tuple] = np.trace(np.matmul(proc_op_total, taus))

    # We need p~^1(abc|xy) = p1(ab|xy) p(c|xyab)
    # First make p(c|xyab) = p(abc|xy) / p(ab|xy)
    cor_pab_xy = np.einsum('ijklmno->ijkmno', cor_pabc_xy)  # p(ab|xy)
    # We now want 1 / p(ab|xy). Where p(ab|xy)=0, we must have p1(ab|xy)=0, because we assume p(c=|0>) != 0 [see p91].
    # This means that p~^1(abc|xy) = p1(ab|xy) p(c|xyab) = 0. Hence we can safely set 1 / p(ab|xy) = 0 for these cases.
    cor_pab_xy_inv = np.reciprocal(cor_pab_xy, out=np.zeros_like(cor_pab_xy), where=cor_pab_xy != 0)
    cor_pc_xyab = np.einsum('ijklmno,ijkmno->ijklmno', cor_pabc_xy, cor_pab_xy_inv)
    # Now make p~^1(c|xy) = sum_a sum_b p1(ab|xy) p(c|xyab).
    cor_ptilde1c_xy = np.einsum('ijkmno,ijklmno->lmno', cor_p1ab_xy, cor_pc_xyab)

    # Alternatively, tracing out c allows to check that a_1 and a_2 ARE independent of y. Yay!

    diff_y = cor_ptilde1c_xy[:, :, :, 0] - cor_ptilde1c_xy[:, :, :, 1]
    return np.sum(np.abs(diff_y)), np.einsum('ijkmno,ijklmno->ijklmno', cor_p1ab_xy, cor_pc_xyab)


def dependence_of_b_on_x_in_phat1(rho_ctb, X1, X2, Y, c_onb):
    """ Returns a measure of the dependence of b on x_1, x_2 in the probability distribution p-hat-1 defined on [p92].
    This is relevant to the one_switch_4mmts scenario, with no setting for the measurement on c."""
    # Make p^1(ab|xy) correlation
    W_CO1 = kron(phi_plus_un, ket0, ket0, phi_plus_un, phi_plus_un, phi_plus_un)
    W_CO1_ordered = reshuffle_kron_vector(W_CO1, (2, 4, 0, 5, 6, 7, 8, 3, 9, 1))
    proc_op_1 = proj(W_CO1_ordered)
    correlation_p1 = np.empty((2,) * 6)
    for setting_outcome_tuple in itertools.product((0, 1), repeat=6):
        a_1, a_2, b, x_1, x_2, y = setting_outcome_tuple
        tau_ctb = rho_ctb.T
        tau_a_1 = kron(proj(X1[x_1][a_1]), proj(X1[x_1][a_1])).T
        tau_a_2 = kron(proj(X2[x_2][a_2]), proj(X2[x_2][a_2])).T
        tau_Btilde = proj(Y[y][b]).T
        tau_Ctilde = proj(
            ket0).T  # conditioning on c = ket0. This should be same as tau_Ctilde = identity, since we're using W_CO1. I checked it, is is true!
        tau_Ttilde = np.identity(2)
        taus = kron(tau_ctb, tau_a_1, tau_a_2, tau_Ctilde, tau_Ttilde, tau_Btilde)
        correlation_p1[setting_outcome_tuple] = np.trace(np.matmul(proc_op_1, taus))
    # Note that correlation_p1 is not normalised (it has normalisation p(c=ket0), where p is generated by proc_op_total). We could normalise, but it isn't necessary.

    # Make p(abc|xy) correlation
    proc_op_total = process_operator_switch()
    correlation_pabc = np.empty((2,) * 7)
    for setting_outcome_tuple in itertools.product((0, 1), repeat=7):
        a_1, a_2, b, c, x_1, x_2, y = setting_outcome_tuple
        tau_ctb = rho_ctb.T
        tau_a_1 = kron(proj(X1[x_1][a_1]), proj(X1[x_1][a_1])).T
        tau_a_2 = kron(proj(X2[x_2][a_2]), proj(X2[x_2][a_2])).T
        tau_Btilde = proj(Y[y][b]).T
        tau_Ctilde = proj(c_onb[c]).T
        tau_Ttilde = np.identity(2)
        taus = kron(tau_ctb, tau_a_1, tau_a_2, tau_Ctilde, tau_Ttilde, tau_Btilde)
        correlation_pabc[setting_outcome_tuple] = np.trace(np.matmul(proc_op_total, taus))

    # The new correlation will be phat1(abc|xy) = p1(a|x) p(c|xa) p(b|xyac)
    # Make p1(a|x)
    correlation_p1ax = np.einsum('ijkmno->ijmno', correlation_p1)[:, :, :, :, 0]  # Is equal to [:, :, :, :, 1] ✓
    # Make p(c|xa) = p(ac|x) / p(a|x)
    correlation_pacx = np.einsum('ijklmno->ijlmno', correlation_pabc)[:, :, :, :, 0]  # p(ac|x)
    correlation_pax = np.einsum('ijlmn->ijmn', correlation_pacx)  # p(a|x)
    correlation_pc_xa = np.einsum('ijlmn,ijmn->ijlmn', correlation_pacx, np.reciprocal(correlation_pax))
    # Make p(b|xyac) = p(abc|xy) / p(ac|x)
    correlation_pb_xyac = np.einsum('ijklmno,ijlmn->ijklmno', correlation_pabc, np.reciprocal(correlation_pacx))
    # Finally, make phat1(abc|xy) = p1(a|x) p(c|xa) p(b|xyac) AND trace out a,c
    correlation_phat1_b_xy = np.einsum('ijmn,ijlmn,ijklmno->kmno', correlation_p1ax, correlation_pc_xa,
                                       correlation_pb_xyac)

    diff_x_1 = correlation_phat1_b_xy[:, 0, :, :] - correlation_phat1_b_xy[:, 1, :, :]  # NOTE this is only the dependence on x_1!
    return np.sum(np.abs(diff_x_1))

    # Gives 0.228, 0.0283, etc. So indeed dependence!


def dependence_of_ac_on_y_in_phacek1(rho_ctb, X1, X2, Y, c_onb):
    """ Returns a measure of the dependence of a,c on y in the probability distribution pˇ1 defined on [p104]. (NOTE this function assumes p(c=0|by)=1/2 and indep of by)
    This is relevant to the one_switch_4mmts scenario, with no setting for the measurement on c.
    NOTE This function ONLY works properly if p(c = |0>)|yb) is nonzero AND INDEP OF y,b, e.g. if CTB = ket_plus tens phi_plus
    """
    # We need to make phacek1 := p(b|y) p^1(a|x,by) p(c|abxy)
    # First make p(abc|xy)
    pabc_xy = make_pabc_xy(rho_ctb, X1, X2, Y, c_onb)
    # Make p(b|y)
    pb_y = np.einsum('ijklmno->kmno', pabc_xy)[:, 0, 0, :]
    # Make p(c|abxy)
    pab_xy = np.einsum('ijklmno->ijkmno', pabc_xy)
    pab_xy_inv = np.reciprocal(pab_xy, out=np.zeros_like(pab_xy), where=pab_xy != 0)
    pc_abxy = np.einsum('ijklmno,ijkmno->ijklmno', pabc_xy, pab_xy_inv)
    # Make p^1(a|x,by)
    p1ab_xy = 2 * make_p1ab_xy_unnormalised(rho_ctb, X1, X2, Y)
    p1b_xy = np.einsum('ijkmno->kmno', p1ab_xy)
    p1b_xy_inv = np.reciprocal(p1b_xy, out=np.zeros_like(p1b_xy), where=p1b_xy != 0)
    p1a_bxy = np.einsum('ijkmno,kmno->ijkmno', p1ab_xy, p1b_xy_inv)
    # Make phacek1(abc|xy)
    phacek1abc_xy = np.einsum('ko,ijkmno,ijklmno->ijklmno', pb_y, p1a_bxy, pc_abxy)

    # Calculate measure of dependence of ac on y
    phacek1ac_xy = np.einsum('ijklmno->ijlmno', phacek1abc_xy)
    dep = np.sum(np.abs(phacek1ac_xy[:, :, :, :, :, 0] - phacek1ac_xy[:, :, :, :, :, 1]))

    return phacek1abc_xy, dep


def III(rho_ctb, X1, X2, Y, c_onb):
    """ See [p106]. """

    # Want to make q(abc|xy) := 1/2 * p1(ac|x)p(b|xya,c=1) + 1/2 p2(ac|x)p(b|xya,c=2)
    p1ab_xy = 2 * make_p1ab_xy_unnormalised(rho_ctb, X1, X2, Y)
    p2ab_xy = 2 * make_p2ab_xy_unnormalised(rho_ctb, X1, X2, Y)
    p1a_x = np.einsum('ijkmno->ijmno', p1ab_xy)[:, :, :, :, 0]
    p2a_x = np.einsum('ijkmno->ijmno', p2ab_xy)[:, :, :, :, 0]
    pabc_xy = make_pabc_xy(rho_ctb, X1, X2, Y, c_onb)
    pac_xy = np.einsum('ijklmno->ijlmno', pabc_xy)
    pac_x = pac_xy[:, :, :, :, :, 0]
    pa_x_inv = reciprocal_or_zero(np.einsum('ijlmn->ijmn', pac_x))
    pc_ax = np.einsum('ijlmn,ijmn->ijlmn', pac_x, pa_x_inv)
    p1ac_x = np.einsum('ijmn,ijlmn->ijlmn', p1a_x, pc_ax)
    p2ac_x = np.einsum('ijmn,ijlmn->ijlmn', p2a_x, pc_ax)

    # Now make p(b|xya,c=1) and p(b|xya,c=2)
    pabc_xy_Z = make_pabc_xy(rho_ctb, X1, X2, Y, z_onb)  # note the z_onb
    pac_xy_Z_inv = reciprocal_or_zero(np.einsum('ijklmno->ijlmno', pabc_xy_Z))
    pb_acxy_Z = np.einsum('ijklmno,ijlmno->ijklmno', pabc_xy_Z, pac_xy_Z_inv)
    pb_a1xy = pb_acxy_Z[:, :, :, 0, :, :, :]  # p(b|xya,c=1)
    pb_a2xy = pb_acxy_Z[:, :, :, 1, :, :, :]  # p(b|xya,c=2)

    # Finally:
    qabc_xy = 1 / 2 * (np.einsum('ijlmn,ijkmno->ijklmno', p1ac_x, pb_a1xy) + np.einsum('ijlmn,ijkmno->ijklmno', p2ac_x, pb_a2xy))

    # Now see if it's equal to pabc_xy
    print(np.sum(np.abs(pabc_xy - qabc_xy)))

    # Gives 4.25 (on rho_ctb=proj(kron(ket_plus, phi_plus)), X1=[z_onb, x_onb], X2=[z_onb, x_onb], Y=[z_onb, x_onb], c_onb=x_onb)
    #  --> so no, q is not equal to p.


def make_p1ab_xy_unnormalised(rho_ctb, X1, X2, Y):
    W_CO1 = kron(phi_plus_un, ket0, ket0, phi_plus_un, phi_plus_un, phi_plus_un)
    W_CO1_ordered = reshuffle_kron_vector(W_CO1, (2, 4, 0, 5, 6, 7, 8, 3, 9, 1))
    proc_op_1 = proj(W_CO1_ordered)
    p1ab_xy = np.empty((2,) * 6)
    for setting_outcome_tuple in itertools.product((0, 1), repeat=6):
        a_1, a_2, b, x_1, x_2, y = setting_outcome_tuple
        tau_ctb = rho_ctb.T
        tau_a_1 = kron(proj(X1[x_1][a_1]), proj(X1[x_1][a_1])).T
        tau_a_2 = kron(proj(X2[x_2][a_2]), proj(X2[x_2][a_2])).T
        tau_Btilde = proj(Y[y][b]).T
        tau_Ctilde = proj(
            ket0).T  # conditioning on c = ket0. This should be same as tau_Ctilde = identity, since we're using W_CO1. I checked it, is is true!
        tau_Ttilde = np.identity(2)
        taus = kron(tau_ctb, tau_a_1, tau_a_2, tau_Ctilde, tau_Ttilde, tau_Btilde)
        p1ab_xy[setting_outcome_tuple] = np.trace(np.matmul(proc_op_1, taus))
    return p1ab_xy


def make_p2ab_xy_unnormalised(rho_ctb, X1, X2, Y):
    W_CO2 = kron(phi_plus_un, ket1, ket1, phi_plus_un, phi_plus_un, phi_plus_un)
    W_CO2_ordered = reshuffle_kron_vector(W_CO2, (2, 4, 0, 7, 8, 5, 6, 3, 9, 1))
    proc_op_2 = proj(W_CO2_ordered)
    p2ab_xy = np.empty((2,) * 6)
    for setting_outcome_tuple in itertools.product((0, 1), repeat=6):
        a_1, a_2, b, x_1, x_2, y = setting_outcome_tuple
        tau_ctb = rho_ctb.T
        tau_a_1 = kron(proj(X1[x_1][a_1]), proj(X1[x_1][a_1])).T
        tau_a_2 = kron(proj(X2[x_2][a_2]), proj(X2[x_2][a_2])).T
        tau_Btilde = proj(Y[y][b]).T
        tau_Ctilde = proj(
            ket0).T  # conditioning on c = ket0. This should be same as tau_Ctilde = identity, since we're using W_CO1. I checked it, is is true!
        tau_Ttilde = np.identity(2)
        taus = kron(tau_ctb, tau_a_1, tau_a_2, tau_Ctilde, tau_Ttilde, tau_Btilde)
        p2ab_xy[setting_outcome_tuple] = np.trace(np.matmul(proc_op_2, taus))
    return p2ab_xy


def make_pabc_xy(rho_ctb, X1, X2, Y, c_onb):
    proc_op_total = process_operator_switch()
    pabc_xy = np.zeros((2,) * 7)

    # Make the needed taus
    tau_dtype = 'complex128' if X1[0].dtype == 'complex' or X1[1].dtype == 'complex' \
                                or X2[0].dtype == 'complex' or X2[1].dtype == 'complex' \
                                or Y[0].dtype == 'complex' or Y[1].dtype == 'complex' \
                                or rho_ctb.dtype == 'complex' or c_onb.dtype == 'complex' \
        else 'float64'
    tau_ctb = rho_ctb.T
    def make_taus_from_settings(X):
        tau = np.empty((2, 2, 4, 4), dtype=tau_dtype)  # a family of 4x4 matrices indexed by two binary indices
        for x, a in itertools.product((0, 1), repeat=2):
            tau[x][a] = kron(proj(X[x][a]), proj(X[x][a])).T
        return tau
    taus_a1 = make_taus_from_settings(X1)
    taus_a2 = make_taus_from_settings(X2)
    taus_Btilde = np.empty((2, 2, 2, 2), dtype=tau_dtype)
    for y, b in itertools.product((0, 1), repeat=2):
        taus_Btilde[y][b] = proj(Y[y][b]).T
    taus_Ctilde = np.array([proj(c_onb[c]).T for c in (0, 1)])
    tau_Ttilde = np.identity(2, dtype=tau_dtype)

    # Make correlation
    for a_1, a_2, b, c, x_1, x_2, y in itertools.product((0, 1), repeat=7):
        taus = kron(tau_ctb, taus_a1[x_1, a_1], taus_a2[x_2, a_2], taus_Ctilde[c], tau_Ttilde, taus_Btilde[y, b])
        born_prob = np.trace(np.matmul(proc_op_total, taus))
        if np.imag(born_prob) > 1e-15:
            print("WARNING - DETECTED A LARGE IMAGINARY VALUE IN PROBABILITY: p(%d,%d,b=%d,c=%d,%d,%d,%d) = %s" % (a_1, a_2, b, c, x_1, x_2, y, str(born_prob)))
        pabc_xy[a_1, a_2, b, c, x_1, x_2, y] = np.real(born_prob)

    # Old code (but more straightforward), of which the above is an optimisation:
    """
    pabc_xy_control = np.zeros((2,) * 7)
    for a_1, a_2, b, c, x_1, x_2, y in itertools.product((0, 1), repeat=7):
        tau_ctb = rho_ctb.T
        tau_a_1 = kron(proj(X1[x_1][a_1]), proj(X1[x_1][a_1])).T
        tau_a_2 = kron(proj(X2[x_2][a_2]), proj(X2[x_2][a_2])).T
        tau_Btilde = proj(Y[y][b]).T
        tau_Ctilde = proj(c_onb[c]).T
        tau_Ttilde = np.identity(2)
        taus = kron(tau_ctb, tau_a_1, tau_a_2, tau_Ctilde, tau_Ttilde, tau_Btilde)
        pabc_xy_control[a_1, a_2, b, c, x_1, x_2, y] = np.trace(np.matmul(proc_op_total, taus))
    assert np.all(pabc_xy_control == pabc_xy)
    """
    return pabc_xy


if __name__ == '__main__':
    ## Showing that p(c | x_1, x_2, y) can generally depend on y (i.e. 'disproving (iii)'):
    """
    tau_ctb = proj(kron(ket_plus, ket0, ket0))
    tau_a_1 = (proj(np.array([1, 0, 0, 0])) + proj(np.array([0, 0, 0, 1]))).T
    # tau_a_2 = (proj(np.array([1, 0, 0, 0])) + proj(np.array([0, 0, 0, 1]))).T
    tau_a_2 = (proj(1 / 2 * np.array([1, 1, 1, 1])) + proj(1 / 2 * np.array([1, -1, -1, 1]))).T
    # tau_a_1 = (proj(1 / 2 * np.array([1, 1, 1, 1])) + proj(1 / 2 * np.array([1, -1, -1, 1]))).T
    tau_Ctilde = proj(ket_plus).T
    tau_Ttilde = np.identity(2)
    tau_Btilde = np.identity(2)
    taus = kron(tau_ctb, tau_a_1, tau_a_2, tau_Ctilde, tau_Ttilde, tau_Btilde)
    process_op = process_operator_switch()
    print(np.trace(np.matmul(process_op, taus)))
    """

    ## Trying to see if p~^1(a_1, a_2, c | x_1, x_2, y) depends on y:
    dep, _ = dependence_of_c_on_y_in_ptilde1(
        rho_ctb=quantum_utils.rho_tcb_0phi,
        # rho_ctb=proj(normalise_vec(np.random.rand(8))),
        X1=[z_onb, quantum_utils.x_onb],  # X1 = [random_real_onb(), random_real_onb()] # TODO see below
        X2=[z_onb, quantum_utils.x_onb],  # TODO change back to z_onb, x_onb when NaN problem resolved
        Y=[quantum_utils.diag1_onb, quantum_utils.diag2_onb],  # Y = [random_real_onb(), random_real_onb()]
        c_onb=quantum_utils.x_onb)  # c_onb = x_onb
    print(dep)

    """phacek1abc_xy, dep = dependence_of_ac_on_y_in_phacek1(
        rho_ctb=proj(kron(ket_plus, phi_plus)),
        # rho_ctb=proj(normalise_vec(np.random.rand(8))),
        X1=[z_onb, x_onb],  # X1 = [random_real_onb(), random_real_onb()] # TODO see below
        X2=[z_onb, x_onb],  # TODO change back to z_onb, x_onb when NaN problem resolved
        Y=[z_onb, x_onb],  # Y = [random_real_onb(), random_real_onb()]
        c_onb=x_onb)  # c_onb = x_onb
    print(dep)"""

    # III(rho_ctb=proj(kron(ket_plus, phi_plus)),
    #     X1=[z_onb, x_onb],
    #     X2=[z_onb, x_onb],
    #     Y=[z_onb, x_onb],
    #     c_onb=x_onb)

    # Gave 0.2972878186211555 for some random ONBs. So definitely dependence between y and c! (If code is correct)
    # For X1=Z,X, X2=diag1,2, Y=Z,X, c_onb=x_onb, and some random rho_ctb, I got 0.2535096933657037.

    # Using X1,X2,Y = random and c_onb = x_onb:
    # rho_ctb = ket0,ket0,ket0: gives 4e-16 ✓
    # rho_ctb = ket+,ket0,ket0: gives 3e-16 ✓
    # rho_ctb = phi+     ,ket0: gives 1.5e-16 ✓ all as expected
    # Now entangle c and b:
    # rho_ctb = 'ikj',phi_plus,ket0: gives 0.0804 and 0.0885 and 0.378.  ✓ NOTE Yay, gives dependence! So this is a candidate for LDCO violation---because the 'Method (I)' proof on [p91] doesn't work for it.
    # TODO left to check this for non-random X1,X2,Y. First solve div by 0 problem
    # Now entangle t and b:
    # rho_ctb = ket+,phi_+          : gives 0.224 and 0.0555 and 0.112 and 0.0997. NOTE Unexpected! But actually makes sense? Maybe?
    # Now try GHZ state (should logically also work, following from fact that CB entangled already works, let alone TB entangled).
    # rho_ctb = GHZ              : gives 0.0347 and 0.283 ✓

    # NOTE See [p93] for the results with non-random X1,X2,Y.